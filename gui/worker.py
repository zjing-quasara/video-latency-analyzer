"""
åå°å·¥ä½œçº¿ç¨‹ - ç›´æ¥å¤åˆ¶è‡ªtemp_delay_gui.pyçš„èƒ½å·¥ä½œçš„ç‰ˆæœ¬
"""
import cv2
import csv
import re
import json
import os
from pathlib import Path
from datetime import datetime
from PyQt5.QtCore import QThread, pyqtSignal
from paddleocr import PaddleOCR
from core.adaptive_ocr import AdaptiveOCREngine
from core.smart_calibrator import SmartCalibrator
from core.smart_roi_detector import SmartROIDetector
from utils.logger import get_logger


class AnalysisWorker(QThread):
    """è§†é¢‘åˆ†æåå°çº¿ç¨‹ - ä½¿ç”¨temp_delay_gui.pyä¸­éªŒè¯è¿‡çš„å®ç°"""
    
    progress = pyqtSignal(int, int)
    log_message = pyqtSignal(str)
    finished = pyqtSignal(bool, str, str)
    
    def __init__(self, video_path, app_roi, use_gpu, resize_ratio, frame_limit, frame_step, treal_format, output_dir=None, phone_log=None, pc_log=None):
        super().__init__()
        self.logger = get_logger('AnalysisWorker')
        self.video_path = video_path
        self.app_roi = app_roi
        self.use_gpu = use_gpu
        self.resize_ratio = resize_ratio
        self.frame_limit = frame_limit
        self.frame_step = frame_step
        self.treal_format = treal_format  # 'standard' æˆ– 'digits'
        self.output_dir = Path(output_dir) if output_dir else Path.home() / "Desktop" / "è§†é¢‘å»¶æ—¶åˆ†æ"
        self.phone_log = phone_log  # æ‰‹æœºç½‘ç»œæ—¥å¿—è·¯å¾„
        self.pc_log = pc_log  # ç”µè„‘ç½‘ç»œæ—¥å¿—è·¯å¾„
        self.ocr_engine = None
        self.adaptive_ocr = None  # è‡ªé€‚åº”OCRå¼•æ“
        self.calibrator = None  # æ™ºèƒ½æ ¡å‡†å™¨
        self.roi_detector = None  # æ™ºèƒ½ROIæ£€æµ‹å™¨
        
        self.logger.info(f"åˆ†æworkerå·²åˆ›å»º: video={Path(video_path).name}, gpu={use_gpu}, ratio={resize_ratio}, limit={frame_limit}, step={frame_step}, format={treal_format}, phone_log={phone_log is not None}, pc_log={pc_log is not None}")
    
    def run(self):
        try:
            self.logger.info("å¼€å§‹è§†é¢‘åˆ†æä»»åŠ¡")
            
            # åˆå§‹åŒ–OCR
            gpu_mode = '0' if self.use_gpu else '-1'
            os.environ['CUDA_VISIBLE_DEVICES'] = gpu_mode
            self.logger.info(f"OCR GPUæ¨¡å¼: {'å¯ç”¨' if self.use_gpu else 'ç¦ç”¨'} (CUDA_VISIBLE_DEVICES={gpu_mode})")
            
            # åˆå§‹åŒ–è‡ªé€‚åº”OCRå¼•æ“ï¼ˆæ›¿ä»£åŸæœ‰OCRï¼‰
            self.log_message.emit("ğŸš€ åˆå§‹åŒ–æ™ºèƒ½OCRå¼•æ“...")
            self.adaptive_ocr = AdaptiveOCREngine(use_gpu=self.use_gpu, lang="en", logger=self.logger)
            self.ocr_engine = self.adaptive_ocr.ocr  # ä¿æŒå…¼å®¹æ€§
            self.logger.info("è‡ªé€‚åº”OCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–æ™ºèƒ½æ ¡å‡†å™¨
            self.calibrator = SmartCalibrator(self.adaptive_ocr, logger=self.logger)
            
            # åˆå§‹åŒ–æ™ºèƒ½ROIæ£€æµ‹å™¨
            self.roi_detector = SmartROIDetector(logger=self.logger)
            
            # ğŸ”§ é˜¶æ®µ1ï¼šè‡ªåŠ¨æ ¡å‡†ï¼ˆä½¿ç”¨å‰10å¸§ï¼‰
            self.log_message.emit("ğŸ”§ é˜¶æ®µ1ï¼šæ™ºèƒ½æ ¡å‡†ä¸­ï¼ˆåˆ†æå‰10å¸§ï¼Œè‡ªåŠ¨å¯»æ‰¾æœ€ä½³å‚æ•°ï¼‰...")
            try:
                calibration_result = self.calibrator.calibrate(
                    video_path=self.video_path,
                    app_roi=self.app_roi,
                    max_frames=10
                )
                self.log_message.emit(
                    f"âœ… æ ¡å‡†å®Œæˆï¼T_appç­–ç•¥: {calibration_result.app_strategy}, "
                    f"T_realç­–ç•¥: {calibration_result.real_strategy}, "
                    f"æˆåŠŸç‡: {calibration_result.success_rate:.1%}"
                )
            except Exception as e:
                self.logger.warning(f"è‡ªåŠ¨æ ¡å‡†å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤ç­–ç•¥: {e}")
                self.log_message.emit("âš ï¸ è‡ªåŠ¨æ ¡å‡†å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
            
            self.log_message.emit("PaddleOCR åˆå§‹åŒ–å®Œæˆ")
            self.logger.info("OCRç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
            success, message, report_folder = self.analyze_video()
            self.logger.info(f"åˆ†æå®Œæˆ: success={success}, folder={report_folder}")
            self.finished.emit(success, message, report_folder)
        except Exception as e:
            import traceback
            error_msg = f"é”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            self.logger.error(f"åˆ†æå¤±è´¥: {error_msg}")
            self.finished.emit(False, error_msg, "")
    
    def detect_real_time_roi(self, frame):
        """åŠ¨æ€æ£€æµ‹ T_realï¼ˆä½¿ç”¨æ™ºèƒ½ROIæ£€æµ‹å™¨ï¼‰"""
        if self.roi_detector:
            # ğŸš€ ä½¿ç”¨æ™ºèƒ½ROIæ£€æµ‹å™¨ï¼ˆè‡ªé€‚åº”å¤šç­–ç•¥ï¼‰
            return self.roi_detector.detect(frame, exclude_roi=self.app_roi)
        
        # é™çº§æ–¹æ¡ˆï¼šç®€å•æ£€æµ‹ï¼ˆä¸åº”è¯¥æ‰§è¡Œåˆ°è¿™é‡Œï¼‰
        return None
    
    def extract_time_from_roi(self, frame, roi, exclude_roi=None):
        """
        ä» ROI æå–æ—¶é—´ï¼ˆä½¿ç”¨è‡ªé€‚åº”OCRï¼‰
        exclude_roi: è¦æ’é™¤çš„åŒºåŸŸï¼ˆç”¨äºé¿å…è¯»å–é‡å çš„T_appå†…å®¹ï¼‰
        """
        if not roi:
            return None
        
        x1, y1, x2, y2 = roi
        h, w = frame.shape[:2]
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        roi_img = frame[y1:y2, x1:x2].copy()
        if roi_img.size == 0:
            return None
        
        # ç¡®å®šROIç±»å‹
        roi_type = "T_real" if exclude_roi else "T_app"
        
        # å¦‚æœæœ‰éœ€è¦æ’é™¤çš„åŒºåŸŸï¼ˆT_appï¼‰ï¼ŒæŠŠå®ƒæ¶‚é»‘
        if exclude_roi:
            ex1, ey1, ex2, ey2 = exclude_roi
            rel_x1 = max(0, ex1 - x1)
            rel_y1 = max(0, ey1 - y1)
            rel_x2 = min(roi_img.shape[1], ex2 - x1)
            rel_y2 = min(roi_img.shape[0], ey2 - y1)
            
            if rel_x1 < rel_x2 and rel_y1 < rel_y2:
                roi_img[rel_y1:rel_y2, rel_x1:rel_x2] = 0
        
        # ç¼©æ”¾ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if self.resize_ratio < 1.0:
            roi_img = cv2.resize(roi_img, (0, 0), fx=self.resize_ratio, fy=self.resize_ratio, 
                               interpolation=cv2.INTER_AREA)
        
        # ğŸš€ ä½¿ç”¨è‡ªé€‚åº”OCRå¼•æ“ï¼ˆè‡ªåŠ¨å°è¯•å¤šç§ç­–ç•¥ï¼‰
        if self.adaptive_ocr:
            time_str = self.adaptive_ocr.extract_time_adaptive(roi_img, roi_type=roi_type)
            return time_str
        
        # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨åŸæœ‰çš„åŸºç¡€OCRï¼ˆä¸åº”è¯¥æ‰§è¡Œåˆ°è¿™é‡Œï¼‰
        return None
    
    def parse_time_to_ms(self, time_str):
        """æ—¶é—´å­—ç¬¦ä¸²è½¬æ¯«ç§’ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰"""
        if not time_str:
            return None
        
        try:
            # æ ¼å¼1: HH:MM:SS.mmm æˆ– HH:MM:SS:mmm
            if ":" in time_str:
                if "." in time_str:
                    hms, ms_part = time_str.split(".")
                else:
                    hms, ms_part = time_str, "0"
                h, m, s = map(int, hms.split(":"))
                ms = int(ms_part.ljust(3, "0")[:3])
                return ((h * 3600 + m * 60 + s) * 1000) + ms
            
            # æ ¼å¼2: çº¯æ•°å­—ï¼ˆHHMMSSMMM æˆ– HHMMSSï¼‰
            digits = "".join(ch for ch in time_str if ch.isdigit())
            
            if len(digits) >= 6:
                h = int(digits[0:2])
                m = int(digits[2:4])
                s = int(digits[4:6])
                ms = int(digits[6:9]) if len(digits) >= 9 else 0
                
                # éªŒè¯åˆæ³•æ€§
                if 0 <= h < 24 and 0 <= m < 60 and 0 <= s < 60 and 0 <= ms < 1000:
                    return ((h * 3600 + m * 60 + s) * 1000) + ms
            
            return None
        except Exception:
            return None
    
    def format_time_display(self, time_str):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºï¼ˆçº¯æ•°å­—è½¬ä¸ºæ ‡å‡†æ ¼å¼ï¼‰"""
        if not time_str:
            return None
        
        # å¦‚æœå·²ç»æ˜¯æ ‡å‡†æ ¼å¼ï¼Œç›´æ¥è¿”å›
        if ":" in time_str:
            return time_str
        
        # çº¯æ•°å­—æ ¼å¼ï¼Œè½¬æ¢ä¸º HH:MM:SS.mmm
        digits = "".join(ch for ch in time_str if ch.isdigit())
        if len(digits) >= 6:
            h = digits[0:2]
            m = digits[2:4]
            s = digits[4:6]
            ms = digits[6:9] if len(digits) >= 9 else "000"
            return f"{h}:{m}:{s}.{ms}"
        
        return time_str
    
    def analyze_video(self):
        """åˆ†æè§†é¢‘ - ç›´æ¥å¤åˆ¶è‡ªtemp_delay_gui.py"""
        video_path = Path(self.video_path)
        frame_step = self.frame_step  # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„æŠ½å¸§é—´éš”
        
        # åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶å¤¹
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        video_name = video_path.stem
        report_folder_name = f"{video_name}_{timestamp}"
        report_dir = self.output_dir / report_folder_name
        report_dir.mkdir(parents=True, exist_ok=True)
        
        self.log_message.emit(f"åˆ›å»ºæŠ¥å‘Šæ–‡ä»¶å¤¹: {report_dir}")
        self.log_message.emit(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path.name}")
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            return False, "æ— æ³•æ‰“å¼€è§†é¢‘", ""
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # æ˜¾ç¤ºåˆ†æèŒƒå›´
        if self.frame_limit == float('inf'):
            self.log_message.emit(f"FPS={fps:.2f}, æ€»å¸§æ•°={total}, å…¨é‡åˆ†æï¼ˆæ•´ä¸ªè§†é¢‘ï¼‰")
            self.log_message.emit(f"æŠ½å¸§é—´éš”: æ¯{frame_step}å¸§ï¼Œé¢„è®¡å¤„ç† {total // frame_step} å¸§")
        else:
            self.log_message.emit(f"FPS={fps:.2f}, æ€»å¸§æ•°={total}, å¤„ç†å‰{self.frame_limit}å¸§")
            self.log_message.emit(f"æŠ½å¸§é—´éš”: æ¯{frame_step}å¸§")
        
        results = []
        annotated_frames = []
        
        # ä¿å­˜CSV
        csv_path = report_dir / f"{report_folder_name}.csv"
        with csv_path.open("w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                "video_name", "frame_idx", "video_time_s",
                "app_time_str", "app_time_ms",
                "real_time_str", "real_time_ms",
                "delay_ms", "status", "error_reason"
            ])
            
            frame_idx = 0
            processed_count = 0
            
            # æ—¶é—´å•è°ƒæ€§éªŒè¯
            last_app_time_ms = None
            last_real_time_ms = None
            
            # è®°ä½ä¸Šæ¬¡æˆåŠŸçš„T_real ROIä½ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼Œå¤±è´¥æ—¶é‡æ–°æ£€æµ‹ï¼‰
            last_successful_real_roi = None
            
            while True:
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡å¸§æ•°é™åˆ¶
                if self.frame_limit != float('inf') and frame_idx > self.frame_limit:
                    break
                
                ret, frame = cap.read()
                if not ret:
                    break
                
                if frame_idx % frame_step != 0:
                    frame_idx += 1
                    continue
                
                # æ›´æ–°è¿›åº¦
                if self.frame_limit != float('inf'):
                    self.progress.emit(frame_idx, int(self.frame_limit))
                else:
                    # å…¨é‡åˆ†ææ˜¾ç¤ºå½“å‰å¸§æ•°
                    self.progress.emit(frame_idx, total)
                
                # æ£€æµ‹å’Œè¯†åˆ« - æ™ºèƒ½ç­–ç•¥
                # 1. ä¼˜å…ˆä½¿ç”¨ä¸Šæ¬¡æˆåŠŸçš„ROIä½ç½®
                if last_successful_real_roi:
                    real_time_str_temp = self.extract_time_from_roi(frame, last_successful_real_roi, exclude_roi=self.app_roi)
                    if real_time_str_temp:
                        # åœ¨ä¸Šæ¬¡ä½ç½®æˆåŠŸè¯†åˆ«åˆ°æ—¶é—´
                        real_roi = last_successful_real_roi
                        real_time_str = real_time_str_temp
                    else:
                        # åœ¨ä¸Šæ¬¡ä½ç½®è¯†åˆ«å¤±è´¥ï¼Œé‡æ–°æ£€æµ‹
                        real_roi = self.detect_real_time_roi(frame)
                        real_time_str = self.extract_time_from_roi(frame, real_roi, exclude_roi=self.app_roi) if real_roi else None
                else:
                    # é¦–æ¬¡æˆ–ä¹‹å‰ä¸€ç›´å¤±è´¥ï¼Œç›´æ¥æ£€æµ‹
                    real_roi = self.detect_real_time_roi(frame)
                    real_time_str = self.extract_time_from_roi(frame, real_roi, exclude_roi=self.app_roi) if real_roi else None
                
                # æ›´æ–°æˆåŠŸçš„ROIä½ç½®
                if real_time_str and real_roi:
                    last_successful_real_roi = real_roi
                
                # è®°å½•æ£€æµ‹çŠ¶æ€
                if real_roi:
                    self.logger.debug(f"å¸§ {frame_idx}: T_real ROI={real_roi}, è¯†åˆ«={'æˆåŠŸ' if real_time_str else 'å¤±è´¥'}")
                else:
                    self.logger.warning(f"å¸§ {frame_idx}: T_real ROIæ£€æµ‹å¤±è´¥")
                
                # è°ƒè¯•ï¼šä¿å­˜ç¬¬ä¸€å¸§å’Œå¤±è´¥å¸§çš„æ£€æµ‹ç»“æœ
                if frame_idx == 0 or (frame_idx <= 100 and real_roi is None and processed_count <= 3):
                    # ä¿å­˜åŸå›¾+ROIæ ‡è®°
                    debug_frame = frame.copy()
                    if real_roi:
                        x1, y1, x2, y2 = real_roi
                        cv2.rectangle(debug_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                        cv2.putText(debug_frame, "T_real ROI (auto)", (x1, y1-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                    else:
                        cv2.putText(debug_frame, f"Frame {frame_idx}: T_real NOT FOUND", (10, 60),
                                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
                    
                    if self.app_roi:
                        x1, y1, x2, y2 = self.app_roi
                        cv2.rectangle(debug_frame, (x1, y1), (x2, y2), (255, 0, 0), 3)
                        cv2.putText(debug_frame, "T_app ROI (manual)", (x1, y1-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)
                    
                    debug_path = report_dir / f"debug_frame_{frame_idx}.png"
                    cv2.imwrite(str(debug_path), debug_frame)
                    
                    # ä¿å­˜ T_app ROI è£å‰ªå›¾ï¼ˆé‡è¦ï¼ï¼‰
                    if self.app_roi:
                        ax1, ay1, ax2, ay2 = self.app_roi
                        app_roi_img = frame[ay1:ay2, ax1:ax2].copy()
                        if app_roi_img.size > 0:
                            cv2.imwrite(str(report_dir / f"debug_T_app_roi_frame_{frame_idx}.png"), app_roi_img)
                    
                    # ä¿å­˜ T_real ROI è£å‰ªå›¾
                    if real_roi:
                        rx1, ry1, rx2, ry2 = real_roi
                        real_roi_img = frame[ry1:ry2, rx1:rx2].copy()
                        if real_roi_img.size > 0:
                            cv2.imwrite(str(report_dir / f"debug_T_real_roi_frame_{frame_idx}.png"), real_roi_img)
                    
                    # åªåœ¨ç¬¬ä¸€å¸§ä¿å­˜é˜ˆå€¼å›¾
                    if frame_idx == 0:
                        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                        cv2.imwrite(str(report_dir / "debug_gray.png"), gray)
                        
                        for thresh in [30, 50, 70, 90]:
                            _, th = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY_INV)
                            cv2.imwrite(str(report_dir / f"debug_threshold_{thresh}.png"), th)
                        
                        self.log_message.emit(f"è°ƒè¯•å›¾å·²ä¿å­˜åˆ°æŠ¥å‘Šæ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬ROIè£å‰ªå›¾ï¼‰")
                
                app_time_str = self.extract_time_from_roi(frame, self.app_roi)
                # real_time_str å·²åœ¨ä¸Šé¢è·å–
                
                # ğŸ“Š è®°å½•è¯†åˆ«æˆåŠŸç‡ç»Ÿè®¡
                if self.calibrator:
                    self.calibrator.record_frame_result(
                        app_success=(app_time_str is not None),
                        real_success=(real_time_str is not None)
                    )
                
                # è®°å½• T_app è¯†åˆ«çŠ¶æ€
                if self.app_roi:
                    if app_time_str:
                        self.logger.debug(f"å¸§ {frame_idx}: T_app è¯†åˆ«æˆåŠŸ='{app_time_str}'")
                    else:
                        self.logger.warning(f"å¸§ {frame_idx}: T_app è¯†åˆ«å¤±è´¥ï¼")
                
                # âœ… éªŒè¯æ—¶é—´åˆæ³•æ€§
                app_error_reason = None
                real_error_reason = None
                
                if app_time_str and self.adaptive_ocr:
                    is_valid, error = self.adaptive_ocr.validate_time(app_time_str)
                    if not is_valid:
                        app_error_reason = "T_appæ— æ•ˆ"
                        self.logger.warning(f"å¸§ {frame_idx}: T_appæ— æ•ˆæ—¶é—´ ('{app_time_str}')")
                
                if real_time_str and self.adaptive_ocr:
                    is_valid, error = self.adaptive_ocr.validate_time(real_time_str)
                    if not is_valid:
                        real_error_reason = "T_realæ— æ•ˆ"
                        self.logger.warning(f"å¸§ {frame_idx}: T_realæ— æ•ˆæ—¶é—´ ('{real_time_str}')")
                
                # æ ¼å¼åŒ–æ˜¾ç¤ºï¼ˆçº¯æ•°å­—è½¬ä¸ºæ ‡å‡†æ ¼å¼ï¼‰
                app_time_str_display = self.format_time_display(app_time_str) if app_time_str else None
                real_time_str_display = self.format_time_display(real_time_str) if real_time_str else None
                
                # å¦‚æœæ—¶é—´å¼‚å¸¸ï¼Œæ ‡è®°ä¸ºwrong
                if app_error_reason:
                    app_time_str_display = f"{app_time_str} (wrong)"
                if real_error_reason:
                    real_time_str_display = f"{real_time_str} (wrong)"
                
                # è®¡ç®—å»¶æ—¶
                video_time_s = frame_idx / fps if fps > 0 else None
                app_time_ms = self.parse_time_to_ms(app_time_str) if app_time_str else None
                real_time_ms = self.parse_time_to_ms(real_time_str) if real_time_str else None
                
                # ä¿å­˜åŸå§‹è¯†åˆ«ç»“æœï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
                if not app_time_str_display:
                    app_time_str_display = app_time_str
                if not real_time_str_display:
                    real_time_str_display = real_time_str
                
                # æ—¶é—´å•è°ƒæ€§éªŒè¯æ ‡è®°
                app_time_wrong = False
                real_time_wrong = False
                
                if app_time_ms is not None and last_app_time_ms is not None:
                    if app_time_ms < last_app_time_ms:
                        app_error_reason = (app_error_reason + "; " if app_error_reason else "") + "æ—¶é—´å€’é€€"
                        self.log_message.emit(
                            f"âš ï¸ å¸§ {frame_idx}: T_appæ—¶é—´å€’é€€ï¼Œæ ‡è®°ä¸º(wrong)"
                        )
                        app_time_wrong = True
                        if "(wrong)" not in app_time_str_display:
                            app_time_str_display = f"{app_time_str} (wrong)"
                        # ä¸ç”¨äºå»¶æ—¶è®¡ç®—ï¼Œä½†ä¿ç•™æ˜¾ç¤º
                        app_time_ms = None
                
                if real_time_ms is not None and last_real_time_ms is not None:
                    if real_time_ms < last_real_time_ms:
                        real_error_reason = (real_error_reason + "; " if real_error_reason else "") + "æ—¶é—´å€’é€€"
                        self.log_message.emit(
                            f"âš ï¸ å¸§ {frame_idx}: T_realæ—¶é—´å€’é€€ï¼Œæ ‡è®°ä¸º(wrong)"
                        )
                        real_time_wrong = True
                        if "(wrong)" not in real_time_str_display:
                            real_time_str_display = f"{real_time_str} (wrong)"
                        # ä¸ç”¨äºå»¶æ—¶è®¡ç®—ï¼Œä½†ä¿ç•™æ˜¾ç¤º
                        real_time_ms = None
                
                # æ›´æ–°ä¸Šä¸€å¸§æ—¶é—´æˆ³ï¼ˆåªæœ‰æ­£ç¡®çš„æ‰æ›´æ–°ï¼‰
                if app_time_ms is not None and not app_time_wrong:
                    last_app_time_ms = app_time_ms
                if real_time_ms is not None and not real_time_wrong:
                    last_real_time_ms = real_time_ms
                
                delay_ms = None
                status = "ok"
                if app_time_ms is None:
                    status = "app_fail"
                if real_time_ms is None:
                    status = "real_fail" if status == "ok" else "both_fail"
                if app_time_ms is not None and real_time_ms is not None:
                    delay_ms = app_time_ms - real_time_ms
                
                # åˆå¹¶é”™è¯¯åŸå› 
                error_reasons = []
                if app_error_reason:
                    error_reasons.append(app_error_reason)
                if real_error_reason:
                    error_reasons.append(real_error_reason)
                combined_error = "; ".join(error_reasons) if error_reasons else ""
                
                # ä¿å­˜åˆ° CSVï¼ˆä½¿ç”¨å¸¦æ ‡è®°çš„æ˜¾ç¤ºå€¼ï¼‰
                writer.writerow([
                    video_path.name, frame_idx,
                    f"{video_time_s:.6f}" if video_time_s is not None else "",
                    app_time_str_display or "", app_time_ms or "",
                    real_time_str_display or "", real_time_ms or "",
                    delay_ms if delay_ms is not None else "", status, combined_error
                ])
                
                # æ”¶é›†æ•°æ®ï¼ˆä½¿ç”¨å¸¦æ ‡è®°çš„æ˜¾ç¤ºå€¼ï¼‰
                results.append({
                    'frame_idx': frame_idx,
                    'video_time_s': video_time_s,
                    'app_time_str': app_time_str_display,
                    'real_time_str': real_time_str_display,
                    'delay_ms': delay_ms,
                    'status': status,
                    'app_time_wrong': app_time_wrong,
                    'real_time_wrong': real_time_wrong,
                    'error_reason': combined_error
                })
                
                # ç»˜åˆ¶æ ‡å®šå›¾
                annotated = frame.copy()
                if self.app_roi:
                    x1, y1, x2, y2 = self.app_roi
                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (255, 0, 0), 2)
                    label = f"T_app: {app_time_str_display}" if app_time_str_display else "T_app: N/A"
                    cv2.putText(annotated, label, (x1, y1 - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
                
                if real_roi:
                    x1, y1, x2, y2 = real_roi
                    # å¦‚æœæ—¶é—´é”™è¯¯ï¼Œç”¨çº¢è‰²æ¡†æ ‡è®°
                    color = (0, 0, 255) if real_time_wrong else (0, 255, 0)
                    cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
                    label = f"T_real: {real_time_str_display}" if real_time_str_display else "T_real: N/A"
                    cv2.putText(annotated, label, (x1, y1 - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                
                if delay_ms is not None:
                    delay_text = f"Delay: {delay_ms}ms"
                    cv2.putText(annotated, delay_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                elif real_time_wrong or app_time_wrong:
                    # æ˜¾ç¤ºé”™è¯¯æ ‡è®°
                    error_text = "OCR Error (wrong)"
                    cv2.putText(annotated, error_text, (10, 30),
                               cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                
                annotated_frames.append(annotated)
                
                # æ—¥å¿—
                if status == "ok":
                    self.log_message.emit(
                        f"å¸§ {frame_idx}: T_app={app_time_str}, T_real={real_time_str}, å»¶æ—¶={delay_ms}ms"
                    )
                else:
                    self.log_message.emit(f"å¸§ {frame_idx}: {status}")
                
                frame_idx += 1
                processed_count += 1
            
            cap.release()
        
        self.log_message.emit(f"å¤„ç†å®Œæˆï¼Œå…± {processed_count} å¸§")
        self.log_message.emit("CSVæŠ¥å‘Šå·²ä¿å­˜: " + csv_path.name)
        self.logger.info(f"CSVå·²ä¿å­˜: {csv_path}")
        
        # å¤„ç†ç½‘ç»œæ—¥å¿—åŒ¹é…
        merged_csv_path = None
        if self.phone_log or self.pc_log:
            self.log_message.emit("æ­£åœ¨åŒ¹é…ç½‘ç»œæ—¥å¿—...")
            self.logger.info("å¼€å§‹ç½‘ç»œæ•°æ®åŒ¹é…")
            try:
                from core.network_matcher import match_network_logs
                
                merged_csv_path = report_dir / f"{report_folder_name}_with_network.csv"
                match_network_logs(
                    video_csv=str(csv_path),
                    phone_csv=self.phone_log,
                    pc_csv=self.pc_log,
                    output_csv=str(merged_csv_path),
                    tolerance=1.0
                )
                
                self.log_message.emit(f"ç½‘ç»œæ•°æ®åŒ¹é…å®Œæˆ: {merged_csv_path.name}")
                self.logger.info(f"ç½‘ç»œæ•°æ®å·²åŒ¹é…: {merged_csv_path}")
            except Exception as e:
                self.log_message.emit(f"âš ï¸ ç½‘ç»œæ•°æ®åŒ¹é…å¤±è´¥: {str(e)}")
                self.logger.error(f"ç½‘ç»œåŒ¹é…å¤±è´¥: {e}")
                merged_csv_path = None
        
        # ç”Ÿæˆæ ‡å®šè§†é¢‘ - å®Œå…¨å¤åˆ¶temp_delay_gui.pyçš„å®ç°
        self.log_message.emit("æ­£åœ¨ç”Ÿæˆæ ‡å®šè§†é¢‘...")
        self.logger.info(f"å¼€å§‹ç”Ÿæˆæ ‡å®šè§†é¢‘ï¼Œannotated_framesæ•°é‡: {len(annotated_frames)}")
        self.log_message.emit(f"annotated_frames æ•°é‡: {len(annotated_frames)}")
        
        video_out_path = report_dir / f"{report_folder_name}.mp4"
        if annotated_frames:
            h, w = annotated_frames[0].shape[:2]
            self.log_message.emit(f"è§†é¢‘å°ºå¯¸: {w}x{h}, FPS: {fps / frame_step:.2f}")
            self.logger.info(f"è§†é¢‘å‚æ•°: size={w}x{h}, fps={fps / frame_step:.2f}")
            
            # å°è¯•å¤šä¸ªç¼–ç å™¨
            codecs = [
                ('avc1', 'H.264 (avc1)'),
                ('H264', 'H.264 (H264)'),
                ('X264', 'H.264 (X264)'),
                ('mp4v', 'MPEG-4'),
                ('XVID', 'XVID'),
            ]
            
            out = None
            used_codec = None
            
            for codec_name, codec_desc in codecs:
                self.logger.info(f"å°è¯•ç¼–ç å™¨: {codec_desc}")
                fourcc = cv2.VideoWriter_fourcc(*codec_name)
                out = cv2.VideoWriter(str(video_out_path), fourcc, fps / frame_step, (w, h))
                
                if out.isOpened():
                    used_codec = codec_desc
                    self.log_message.emit(f"âœ“ ä½¿ç”¨ç¼–ç å™¨: {codec_desc}")
                    self.logger.info(f"ç¼–ç å™¨ {codec_desc} æˆåŠŸæ‰“å¼€")
                    break
                else:
                    self.logger.warning(f"ç¼–ç å™¨ {codec_desc} æ‰“å¼€å¤±è´¥")
                    out.release()
            
            if not out or not out.isOpened():
                error_msg = "æ‰€æœ‰è§†é¢‘ç¼–ç å™¨éƒ½æ— æ³•ä½¿ç”¨ï¼"
                self.log_message.emit(f"âœ— {error_msg}")
                self.logger.error(error_msg)
            else:
                self.log_message.emit(f"ä¿å­˜è·¯å¾„: {video_out_path}")
                self.logger.info(f"VideoWriterè·¯å¾„: {video_out_path}")
                
                for ann_frame in annotated_frames:
                    out.write(ann_frame)
                out.release()
                self.log_message.emit("VideoWriter.release() å®Œæˆ")
                self.logger.info("VideoWriterå·²é‡Šæ”¾")
                
                if video_out_path.exists():
                    size = video_out_path.stat().st_size
                    self.log_message.emit(f"âœ“ æ ‡å®šè§†é¢‘å·²ä¿å­˜: {video_out_path.name} ({size/1024:.2f} KB)")
                    self.logger.info(f"è§†é¢‘æ–‡ä»¶å·²ç”Ÿæˆ: size={size} bytes")
                    
                    # å¦‚æœä½¿ç”¨çš„ä¸æ˜¯H.264ï¼Œå°è¯•ç”¨ffmpegè½¬æ¢
                    if used_codec and 'H.264' not in used_codec:
                        self.log_message.emit(f"æ£€æµ‹åˆ°ä½¿ç”¨éH.264ç¼–ç ({used_codec})ï¼Œå°è¯•è½¬æ¢ä¸ºæµè§ˆå™¨å…¼å®¹æ ¼å¼...")
                        self.logger.info(f"å°è¯•ä½¿ç”¨ffmpegè½¬æ¢è§†é¢‘")
                        
                        try:
                            import subprocess
                            temp_path = video_out_path.parent / f"temp_{video_out_path.name}"
                            
                            # ä½¿ç”¨ffmpegè½¬æ¢ä¸ºH.264
                            cmd = [
                                'ffmpeg', '-y', '-i', str(video_out_path),
                                '-c:v', 'libx264', '-preset', 'fast',
                                '-crf', '23', str(temp_path)
                            ]
                            
                            result = subprocess.run(
                                cmd, 
                                capture_output=True, 
                                timeout=60,
                                creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
                            )
                            
                            if result.returncode == 0 and temp_path.exists():
                                # æ›¿æ¢åŸæ–‡ä»¶
                                video_out_path.unlink()
                                temp_path.rename(video_out_path)
                                new_size = video_out_path.stat().st_size
                                self.log_message.emit(f"âœ“ è§†é¢‘å·²è½¬æ¢ä¸ºH.264æ ¼å¼ ({new_size/1024:.2f} KB)")
                                self.logger.info(f"ffmpegè½¬æ¢æˆåŠŸ: {new_size} bytes")
                            else:
                                self.log_message.emit(f"âš ï¸ ffmpegè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è§†é¢‘")
                                self.logger.warning(f"ffmpegè½¬æ¢å¤±è´¥: {result.stderr.decode('utf-8', errors='ignore')}")
                                if temp_path.exists():
                                    temp_path.unlink()
                        except FileNotFoundError:
                            self.log_message.emit(f"âš ï¸ æœªæ‰¾åˆ°ffmpegï¼Œä½¿ç”¨åŸå§‹è§†é¢‘ï¼ˆæµè§ˆå™¨å¯èƒ½æ— æ³•æ’­æ”¾ï¼‰")
                            self.logger.warning("ffmpegæœªå®‰è£…")
                        except subprocess.TimeoutExpired:
                            self.log_message.emit(f"âš ï¸ ffmpegè½¬æ¢è¶…æ—¶ï¼Œä½¿ç”¨åŸå§‹è§†é¢‘")
                            self.logger.warning("ffmpegè½¬æ¢è¶…æ—¶")
                        except Exception as e:
                            self.log_message.emit(f"âš ï¸ ffmpegè½¬æ¢å¤±è´¥: {str(e)}")
                            self.logger.error(f"ffmpegè½¬æ¢å¼‚å¸¸: {e}")
                else:
                    self.log_message.emit(f"âœ— é”™è¯¯: è§†é¢‘æ–‡ä»¶æœªåˆ›å»ºï¼")
                    self.logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_out_path}")
        else:
            self.log_message.emit("âœ— é”™è¯¯: annotated_frames ä¸ºç©ºï¼Œè·³è¿‡è§†é¢‘ç”Ÿæˆ")
            self.logger.error("annotated_framesä¸ºç©º")
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        self.log_message.emit("æ­£åœ¨ç”Ÿæˆ HTML æŠ¥å‘Š...")
        self.logger.info("å¼€å§‹ç”ŸæˆHTMLæŠ¥å‘Š")
        from core.report_generator import ReportGenerator
        html_path = report_dir / f"{report_folder_name}.html"
        ReportGenerator.generate_html(
            results=results,
            video_filename=f"{report_folder_name}.mp4",
            fps=fps,
            frame_step=frame_step,
            output_path=str(html_path),
            network_csv=str(merged_csv_path) if merged_csv_path else None
        )
        self.log_message.emit("HTMLæŠ¥å‘Šå·²ä¿å­˜: " + html_path.name)
        self.logger.info(f"HTMLæŠ¥å‘Šå·²ä¿å­˜: {html_path}")
        
        # ğŸ“Š è¾“å‡ºè¯†åˆ«ç»Ÿè®¡
        if self.calibrator:
            stats = self.calibrator.get_runtime_stats()
            self.logger.info("=" * 60)
            self.logger.info("è¯†åˆ«ç»Ÿè®¡æŠ¥å‘Š")
            self.logger.info("=" * 60)
            self.logger.info(f"T_app è¯†åˆ«æˆåŠŸç‡: {stats['app_success_rate']:.1%}")
            self.logger.info(f"T_real è¯†åˆ«æˆåŠŸç‡: {stats['real_success_rate']:.1%}")
            self.logger.info(f"æ€»ä½“è¯†åˆ«æˆåŠŸç‡: {stats['overall_success_rate']:.1%}")
            self.logger.info("=" * 60)
            
            self.log_message.emit(
                f"âœ… è¯†åˆ«ç»Ÿè®¡: T_app={stats['app_success_rate']:.1%}, "
                f"T_real={stats['real_success_rate']:.1%}, "
                f"æ€»ä½“={stats['overall_success_rate']:.1%}"
            )
        
        # è¾“å‡ºç­–ç•¥ç»Ÿè®¡
        if self.adaptive_ocr:
            strategy_stats = self.adaptive_ocr.get_statistics()
            self.logger.info(f"æœ€ä½³ç­–ç•¥: {strategy_stats['best_strategy']}")
            self.logger.info(f"ç­–ç•¥ä½¿ç”¨ç»Ÿè®¡: {strategy_stats['strategy_stats']}")
        
        self.logger.info(f"åˆ†æå®Œæˆï¼æŠ¥å‘Šæ–‡ä»¶å¤¹: {report_dir}")
        return True, f"åˆ†æå®Œæˆï¼\næŠ¥å‘Šæ–‡ä»¶å¤¹: {report_dir}", str(report_dir)

